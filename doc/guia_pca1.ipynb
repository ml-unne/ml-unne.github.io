{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Curso de Machine Learning\n","# Reducción de dimensionalidad: PCA\n","## Luis Duarte, Sebastian Filipigh, Magdalena Lucini\n","### Septiembre 2023, FaCENA - UNNE\n","### Contacto:  luis.duarte@comunidad.unne.edu.ar; sfilipigh@comunidad.unne.edu.ar; mmlucini@comunidad.unne.edu.ar"],"metadata":{"id":"rdihcMLuUR5-"}},{"cell_type":"markdown","source":["**Objetivos:**\n","\n","*   Aplicar Análisis de Componentes Principales (PCA) a situaciones con datos reales.\n","*   Realizar análisis gráfico de resultados.\n","*   Producir estimaciones a partir de las PCAs.\n"],"metadata":{"id":"O3wM7skYVCa9"}},{"cell_type":"markdown","source":["**Antes de empezar:**\n","\n","Necesitamos importar las siguientes librerías:"],"metadata":{"id":"AMJoyUEtW6at"}},{"cell_type":"code","source":["#!pip install basemap\n","import numpy as np\n","%matplotlib inline\n","%pylab inline\n","from matplotlib import pyplot as plt\n","import pandas as pd\n","import io\n","import torch\n","import seaborn as sns\n","from mpl_toolkits.basemap import Basemap\n","from google.colab import files"],"metadata":{"id":"jhILkzhaXMFN","executionInfo":{"status":"error","timestamp":1694386495817,"user_tz":180,"elapsed":624,"user":{"displayName":"Magdalena Lucini","userId":"00252515537668408425"}},"colab":{"base_uri":"https://localhost:8080/","height":383},"outputId":"99d9b1ad-89d8-4c47-ecaf-b03a284165f3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Populating the interactive namespace from numpy and matplotlib\n"]},{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-217c1e84ebac>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmpl_toolkits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasemap\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBasemap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mpl_toolkits.basemap'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"markdown","source":["## Primera parte: Construcción de las Componentes Principales\n"],"metadata":{"id":"1s2co6onXYOX"}},{"cell_type":"markdown","source":["1.1) Importe la base de datos."],"metadata":{"id":"BHRhVgonX4qJ"}},{"cell_type":"code","source":["uploaded = files.upload()"],"metadata":{"id":"4zNJ7Eu3YZIT","colab":{"base_uri":"https://localhost:8080/","height":175},"executionInfo":{"status":"error","timestamp":1694386477560,"user_tz":180,"elapsed":291,"user":{"displayName":"Magdalena Lucini","userId":"00252515537668408425"}},"outputId":"fc4c2c74-0834-4e84-e0e3-4b7a37e9b30e"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-ed2fd71b4a2f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'files' is not defined"]}]},{"cell_type":"code","source":["bancos = pd.read_csv(io.BytesIO(uploaded['bancos.csv']))"],"metadata":{"id":"oke_6mEJa18O"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["*   Observe qué variables tiene la base de datos.\n","*   Obtenga las medidas de resumen para las variables.\n"],"metadata":{"id":"ZZey7RwrbncZ"}},{"cell_type":"code","source":["bancos"],"metadata":{"id":"M29mVZZ0bZVV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bancos.describe()"],"metadata":{"id":"ifYOLhBubYoG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["La base de datos \"bancos.csv\" corresponde a 50 empresas argentinas que cotizan en bolsa, en ella se encuentran los siguientes indicadores calculados:\n","\n","LIQACID : Liquidez ácida ((Act.Cte. - Bienes de Cambio)/Pasivo Cte)\\\n","SOLVENC : Solvencia (Activo Total/Pasivo Total)\\\n","PROPACT : Propiedad del Activo (Patrimonio Neto/Activo)\\\n","PNOCOR :Pasivo No Cte./Activo,\\\n","AUTOFIN :Autofinanciación (Utilidades no distribuidas/Activo),\\\n","INMACT :Inmovilización del Activo (Activo no corriente/Activo),\\\n","INMPN :Inmovilización del Patrim. Neto (Activo no corriente/P.Neto),\\\n","RENTECO :Rentabilidad Económica (Utilidad antes de impuestos/Activo Total)."],"metadata":{"id":"tXHeH9DIb7RH"}},{"cell_type":"markdown","source":["La matriz de datos $X$ es de clase $50\\times 8$: el dataset completo con 50 bancos en $\\mathbb{R}^{8}$ (8 variables)\n","\n","$$X =\\begin{bmatrix}\n","x_{1,1} & \\cdots &  x_{1,8}\\\\\n","\\vdots & \\ddots & \\vdots \\\\\n","x_{50,1} & \\cdots &  x_{50,8}\n","\\end{bmatrix} = \\begin{bmatrix}\n","x_{1}\\\\\n","\\vdots  \\\\\n","x_{50}\n","\\end{bmatrix} $$\n","\n","donde cada $x_i =(x_{i,1}, \\cdots ,  x_{i,8} )$\n","\n","\n","Notar que NO se considera ninguna variable respuesta.\n","\n","Conforme a la teoría del PCA, es esencial que los datos estén centrados.\n","\n","* Calculemos el vector media 8-dimensional (en $\\mathbb{R}^{8}$, un vector fila que contiene los promedios de cada variable).\n","\n"," \\begin{align*}\n","\\bar{x}=& \\frac{1}{50} \\sum_{i=1}^{50} x_i \\\\\n","= & \\frac{1}{50} \\sum_{i=1}^{50}(x_{i,1}, \\cdots ,  x_{i,8} )\\\\\n","=& (\\bar{x}_1, \\ldots ,\\bar{x}_{8} )\n","\\end{align*}\n"],"metadata":{"id":"yGAZFc_zj3Ym"}},{"cell_type":"markdown","source":["\n","* Se consideran los datos centrados $X_c$: cada observación (fila) se le resta el vector de medias (es lo mismo que a cada columna se le reste la media de la columna).\n","\n","\\begin{align*}\n","X_c = & \\begin{bmatrix}\n","(x_{1,1}-\\bar{x}_1) & \\ldots &  (x_{1,8}-\\bar{x}_{8})\\\\\n","\\vdots & \\ddots & \\vdots \\\\\n","(x_{50,1}-\\bar{x}_1) & \\ldots &  (x_{50,8}- \\bar{x}_{8})\n","\\end{bmatrix}\\\\\n","= & \\begin{bmatrix}\n","(x_{1}-\\overline{x})\\\\\n","\\vdots  \\\\\n","(x_{n}-\\overline{x})\n","\\end{bmatrix}\n","\\end{align*}\n","\n","donde cada $x_i =(x_{i,1}, \\ldots ,  x_{i,50} )$\n","\n"],"metadata":{"id":"yifykUXTmih1"}},{"cell_type":"code","source":["bancos=bancos.drop(bancos.columns[0], axis=1)\n","X= torch.Tensor(bancos.values)\n"],"metadata":{"id":"wdrg0dAzsn1u","colab":{"base_uri":"https://localhost:8080/","height":192},"executionInfo":{"status":"error","timestamp":1694386462899,"user_tz":180,"elapsed":292,"user":{"displayName":"Magdalena Lucini","userId":"00252515537668408425"}},"outputId":"bfdbb3e2-3167-483d-dcf5-369099e2deb8"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-8648e40f304e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbancos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbancos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbancos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbancos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'bancos' is not defined"]}]},{"cell_type":"code","source":[" #Centrar los datos\n","X_mean = torch.mean(X, 0)\n","Xc= X - X_mean.expand_as(X)"],"metadata":{"id":"RNThPzJutsvs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_mean"],"metadata":{"id":"mZ2bkzl0uCc5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* La matriz de var-covarianzas de todo el dataset.\n","$$S= \\frac{1}{n-1}X_c^{t}. X_c$$\n","\n","\n","- Representa la dispersión de los datos alrededor del vector promedio."],"metadata":{"id":"cJdMKJaLuhCB"}},{"cell_type":"code","source":["S=1/49*Xc.t()@Xc\n","S"],"metadata":{"id":"ZnOu2lmMxybN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["S.diag()"],"metadata":{"id":"5LM9UyV2xwmL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Como las variables no presentan escalas similares (esto se observa con la comparación de las varianzas), es necesario trabajar con los datos escalados. Por tanto, en lugar de trabajar con la matriz de varianzas y covarianzas, trabajaremos con la matriz de correlación.\n","\n","$$R=D^{-1/2}SD^{-1/2}$$\n","donde $D=\\text{diag}(S_{1,1}, S_{2,2}, \\ldots, S_{8,8})$."],"metadata":{"id":"pUgRtvmoxrLK"}},{"cell_type":"code","source":["D=torch.diag(S.diag())\n","R=torch.inverse(torch.sqrt(D))@S@torch.inverse(torch.sqrt(D))\n","R"],"metadata":{"id":"xBmcluJL0tt0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Más facil:\n"],"metadata":{"id":"Lk-xEcSv10qF"}},{"cell_type":"code","source":["R=torch.corrcoef(X.t())\n","R"],"metadata":{"id":"e4mo--OI1IDi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","* Se calculan los ejes de dispersión ortogonales:\n","- Los vectores $v_1,v_2,...,v_{8}$ (en $R^{8}$, de norma 1) y sus valores propios $\\lambda_1,\\lambda_2,...,\\lambda_{8}$.\n","- $\\lambda_1,\\lambda_2,...,\\lambda_{8}$: Valores propios ordenados de forma decreciente.\n","*Se eligen los primeros $k$  (con $k<8$).\n","* Estos vectores definen un nuevo espacio de dimensión $k$.\n","- Se construye una matriz $W$ (tamaño $8\\times k$) donde cada columna es un vector propio normalizado (de norma o longitud 1)."],"metadata":{"id":"095pbb8A40wT"}},{"cell_type":"code","source":[" # Calcular autovalores y autovectores\n","autovalores, autovectores = torch.linalg.eig(R)\n","autovalores"],"metadata":{"id":"ShZeVxPn8BqO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Ordenar autovalores y autovectores por los autovalores en orden descendente\n","autovalores = torch.real(autovalores)\n","orden = torch.argsort(autovalores, descending=True)\n","autovalores_ordenados=autovalores[orden]\n","autovectores_ordenados = autovectores[:,orden]\n","autovalores_ordenados"],"metadata":{"id":"6Rw8jcW8-AIK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Proporción de Variabilidad Explicada\n","Prop=autovalores_ordenados/torch.sum(autovalores)\n","Prop"],"metadata":{"id":"m7xS3C4dDzxD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Proporción acumulada de Variabilidad Explicada\n","torch.cumsum(Prop,dim=0)"],"metadata":{"id":"87ZIYQJQLvRl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Gráfico de Sedimentación\n","plt.figure(figsize=(10, 6))\n","plt.plot(range(1, len(Prop) + 1), Prop, marker='o', linestyle='-', color='b')\n","plt.xlabel('Número de Componentes Principales')\n","plt.ylabel('Proporción de Varianza Explicada')\n","plt.title('Gráfico de Sedimentación PCA')\n","plt.grid(True)\n","plt.show()"],"metadata":{"id":"phHh-YYWEedc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## ¿Cuántas componentes seleccionamos?\n","### Algunos criterios:\n","\n","*   **Gráfico de sedimentación:** elegir las componentes (ordenadas de mayor a menor) hasta donde la pendiente comienza a nivelarse.\n","*   Seleccionar las componentes hasta cubrir un porcentaje determinado de la varianza.\n","*   **Establecer una cota mínima**; por ejemplo la varianza media. En el caso de trabajar con las variables estandarizadas: $\\lambda \\geq 1$."],"metadata":{"id":"-soa8TmXzhIH"}},{"cell_type":"code","source":[" #Seleccionar las 3 principales componentes\n","comp_princ=torch.real(autovectores_ordenados[:,:3])\n","nombres_filas = bancos.columns.tolist()\n","nombres_columnas = [\"CP1\", \"CP2\", \"CP3\"]\n","PCAs=pd.DataFrame(comp_princ.numpy(), index=nombres_filas, columns=nombres_columnas)\n","PCAs\n"],"metadata":{"id":"pzm79QCdSxkf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Todo lo hecho hasta aquí puede realizarse utilizando la función PCA de sklearn."],"metadata":{"id":"A1zr-4z73dER"}},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","from sklearn.decomposition import PCA\n","\n","scaler = StandardScaler()\n","scaled_data = scaler.fit_transform(bancos)\n","pca = PCA()\n","pca.fit(scaled_data)\n"],"metadata":{"id":"sakWyVbBeD5Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Varianza Explicada por las componentes\n","pca.explained_variance_"],"metadata":{"id":"xEN_hi_PvGAY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Proporción de Varianza Explicada\n","PVE=pca.explained_variance_ratio_\n","PVE"],"metadata":{"id":"XoF3S4hZvSkE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Proporción Acumulada de Varianza Explicada\n","np.cumsum(PVE)"],"metadata":{"id":"aEoz81AUv1gF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Nos quedamos con las primeras 3 componentes\n","pca = PCA(n_components=3)\n","pca.fit(scaled_data)\n","PCAs2=pca.components_"],"metadata":{"id":"MzGpsDx_weBh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* Graficamos las cargas de las variables en la primera componente."],"metadata":{"id":"OZ_Gvy7myd6O"}},{"cell_type":"code","source":["component_number = 1  # 0 para la primera componente, 1 para la segunda, etc.\n","plt.figure(figsize=(10, 6))\n","plt.bar(range(PCAs2.shape[1]), PCAs2[component_number, :])\n","plt.xlabel('Variables originales')\n","plt.ylabel('Peso en la Componente Principal')\n","plt.title(f'Cargas de las variables en la Componente Principal {component_number + 1}')\n","plt.xticks(range(PCAs2.shape[1]), bancos.columns.tolist())\n","plt.grid(axis='y')\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"kK23pnNpyad1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* Veamos los datos proyectados en el nuevo espacio generado por las tres primera componentes."],"metadata":{"id":"h5deeFAJ3OSE"}},{"cell_type":"code","source":["\n","data_new = pca.fit_transform(scaled_data) #Proyección de los datos en las nuevas componentes\n","\n","# Visualizar datos en las primeras dos componentes\n","plt.figure(figsize=(10, 6))\n","plt.scatter(data_new[:, 0], data_new[:, 1], edgecolors='k', cmap=plt.cm.get_cmap('jet'))\n","plt.xlabel('Componente Principal 1')\n","plt.ylabel('Componente Principal 2')\n","plt.title('Representación de los datos en las primeras dos Componentes Principales')\n","plt.grid(True)\n","plt.axhline(0, color='black',linewidth=0.5)\n","plt.axvline(0, color='black',linewidth=0.5)\n","#plt.colorbar()\n","plt.show()"],"metadata":{"id":"OmsGYOxf2dM_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Segunda parte: Aplicación de reducción de dimensiones a datos climáticos."],"metadata":{"id":"ut9bz2f330Rk"}},{"cell_type":"markdown","metadata":{"id":"-ZC8Je5WCy6S"},"source":["2.1) Importe el segundo conjunto de datos: SST.csv, el cual corresponde a las SST promedios (en Enero) en el golfo de México, para cada año entre 1998 y 2015. ¿Cuáles son las filas y columnas de este nuevo conjunto de datos?"]},{"cell_type":"code","source":["#from google.colab import files\n","uploaded = files.upload()"],"metadata":{"id":"utH6kPVJ54fE"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HYwVAn_T3CNd"},"outputs":[],"source":["SST = pd.read_csv(io.BytesIO(uploaded['SST.csv']))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8skzvXPPDEVX"},"outputs":[],"source":["# Hechemos un vistazo a la tabla\n","SST"]},{"cell_type":"markdown","metadata":{"id":"nS-A0VBFF1Z8"},"source":["2.2) Usando las funciones *corrcoef* y *pcolor*, calcule y grafique la matriz de correlaciones entre los 1595 píxeles de SST."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z1KNw1xaDFLN"},"outputs":[],"source":["# calculamos la matriz de correlaciones\n","corr_sst = corrcoef(SST.T)\n","# plot the correlation matrix\n","pcolor(corr_sst, cmap='bwr', vmin=-1, vmax=1)\n","title('Correlación de la SST en el Golfo de México', size=20)\n","colorbar()\n"]},{"cell_type":"markdown","metadata":{"id":"A6_C6UnkJJY7"},"source":["2.3) Luego, representamos gráficamente el mapa de correlación entre la SST en el píxel número 1300 y los otros 1594 píxeles. También mostramos la ubicación del píxel número 1300. Necesitaremos cargar la base de datos 'data1.csv' que contiene las coordenadas de los píxeles."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OsbzWTdzJIDc"},"outputs":[],"source":["# Importamos 'data1.csv'\n","uploaded = files.upload()"]},{"cell_type":"code","source":["data1=pd.read_csv(io.BytesIO(uploaded['data1.csv']))"],"metadata":{"id":"HFiaLzh_IMYu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Definimos una función que nos permita graficar:\n","# function to plot images\n","def plot_im(lon, lat, im, size_points, var_name, cmap, vmin, vmax):\n","\n","    # transform to arrays (just in case)\n","    lon = array(lon)\n","    lat = array(lat)\n","    im = array(im)\n","\n","    # Mercator projection (for small zone)\n","    m = Basemap(projection='merc', llcrnrlat=nanmin(lat), urcrnrlat=nanmax(lat),\\\n","                llcrnrlon=nanmin(lon), urcrnrlon=nanmax(lon), lat_0=(nanmax(lat)+nanmin(lat))*0.5,\\\n","                lon_0=(nanmax(lon)+nanmin(lon))*0.5, resolution='l')\n","    # you can use other projections (see https://matplotlib.org/basemap/users/mapsetup.html)\n","\n","    # transform (lon,lat) to (x,y)\n","    x,y = m(lon,lat)\n","\n","    # plot\n","    im = ma.masked_where(isnan(im), im)\n","    res = m.scatter(x, y, size_points, im, 'o', alpha=1, cmap=cmap, lw=0, vmin=vmin, vmax=vmax)\n","    m.drawcoastlines()\n","    m.fillcontinents()\n","    parallels = linspace(ceil(nanmin(lat)), floor(nanmax(lat)), 1+int(floor(nanmax(lat))-ceil(nanmin(lat))))\n","    meridians = linspace(ceil(nanmin(lon)), floor(nanmax(lon)), 1+int(floor(nanmax(lon))-ceil(nanmin(lon))))\n","    m.drawparallels(parallels, labels=[1,0,0,1], fontsize=10)\n","    m.drawmeridians(meridians, labels=[1,0,0,1], fontsize=10)\n","    cb = m.colorbar(res, location=\"right\")\n","    cb.set_label(var_name, fontsize=20)"],"metadata":{"id":"39AC1xqoQNKh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# graficamos la correlación entre un píxel y los demás.\n","plt.figure(figsize=(15, 6))\n","plot_im(data1.lon, data1.lat, corr_sst[1300,:], 70, 'Correlation', cmap='bwr', vmin=-1, vmax=1)\n","title('Correlación entre la SST del píxel 1300 y las demás', size=20)\n","\n","# print las coordenadas del píxel de interés\n","print('Longitud: ', str(360-data1.lon[1300]))\n","print('Latitud: ', str(data1.lat[1300]))"],"metadata":{"id":"NjyXIJ3sIPP2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y_LGwRyY-sMQ"},"source":["**Tarea:** Realice el mismo análisis para los píxeles 100 y 1000."]},{"cell_type":"markdown","metadata":{"id":"peluaU9UTLcR"},"source":["2.3) Calcule las primeras 10 PCA de la SST en el Golfo de México y trace el gráfico de sedimentación para la varianza explicada acumulada. ¿Cuántas componentes serían necesarias para explicar la variabilidad de la SST? (Hacer)."]},{"cell_type":"markdown","metadata":{"id":"40wnft4E_a8T"},"source":["2.4) Trace las CPs que considere, almacenadas en SST_PCA.components_, utilizando la función *plot_im*. ¿Qué destacan las CPs? (Hacer)"]},{"cell_type":"markdown","metadata":{"id":"oK15RCr1X6pE"},"source":["2.5) Para finalizar, reconstruya el mapa de SST en enero de 1998 (es decir, la primera fila del conjunto de datos) utilizando las primeras $k$ CPs consideradas en los ítems anteriores. Para ello, proyecta el conjunto de datos original en el subespacio de dimensión $k$, utilizando la función de *transform* del objeto SST_PCA. Ten en cuenta que debes agregar la media de la SST al mapa reconstruido. (Hacer)"]}]}